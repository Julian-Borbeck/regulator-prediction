{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Prediction of Regulator Function \n",
    "\n",
    "*Author: Julian Borbeck*\n",
    "\n",
    "This notebook contains the documentation of analyses done on LysR family transcription factors as a model for prokaryotic Transcription.\n",
    "\n",
    "Regulators of the LysR family are among the most abundant prokaryotic transcription factors<cite>[1]</cite>. They can also act as either global or local regulators which can repress or activate the transcription of genes<cite>[1]</cite>. The goal of this study was to investigate the relation of function and phylogeny of these regulators, aswell as create a model to predict the function of LysR family regulators based on sequence information.\n",
    "\n",
    "## Obtaining Data\n",
    "\n",
    "Sequences of LysR family regulators with added information about the function of these regulators were obtained from www.uniprot.org/ using the following searches:\n",
    "\n",
    "* https://www.uniprot.org/uniprot/?query=keyword%3A%22Activator+%5BKW-0010%5D%22+LysR&sort=score\n",
    "* https://www.uniprot.org/uniprot/?query=keyword%3A%22Repressor+%5BKW-0678%5D%22+LysR&sort=score\n",
    "\n",
    "Data was obtained as two .gff files. Information about the position of the LysR domain was retrieved from these files, alongside the Uniprot Protein Identifiers.\n",
    "The LysR domain is the domain, which interacts closely with the DNA. With the Protein identifiers and Domain positions the FASTA sequences of the LysR domains were retrieved using the Uniprot Retrieve/ID mapping service.\n",
    "\n",
    "[1] Maddocks, S.; Oyston, P.; Microbiology 2008. 154:3609â€“3623"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Prepare data for Uniprot Retrieve/ID mapping"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "12760 1340\n",
      "59\n",
      "12701 1281\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import math\n",
    "import os\n",
    "\n",
    "# import .gff files obtained from uniprot into pandas dataframe\n",
    "path = os.path.dirname(__file__)\n",
    "Activator = pd.read_csv(os.path.join(path,\"uniprotActivator_all.gff\"), sep= \"\\t\",header= None)\n",
    "Repressor = pd.read_csv(os.path.join(path,\"uniprotRepressor_all.gff\"), sep=\"\\t\",header= None)\n",
    "\n",
    "\n",
    "\n",
    "# instance list of Activators and Repressors for export\n",
    "Activators =[]\n",
    "Repressors =[]\n",
    "\n",
    "# retrieve relevant data from Dataframe\n",
    "for i in range(0,len(Activator)):\n",
    "\n",
    "    name = str(Activator[0][i]) #get regulator ID\n",
    "    \n",
    "    #add Domain sequence information\n",
    "    name +=\"[\"\n",
    "    if(not math.isnan(Activator[3][i])): #check for empty dataframe cell\n",
    "        name += str(int(Activator[3][i]))\n",
    "    name += \"-\"\n",
    "    if (not math.isnan(Activator[4][i])):\n",
    "        name += str(int(Activator[4][i]))\n",
    "    name += \"]\"\n",
    "    function = Activator[8][i]\n",
    "    \n",
    "    # check if domain is part of the LysR family\n",
    "    if( \"HTH lysR-type\" in str(function)):\n",
    "        if(name not in Activators):\n",
    "            Activators +=[name]\n",
    "\n",
    "for i in range(0,len(Repressor)):\n",
    "\n",
    "    name = str(Repressor[0][i])\n",
    "    name += \"[\"\n",
    "    if (not math.isnan(Repressor[3][i])):\n",
    "        name += str(int(Repressor[3][i]))\n",
    "    name += \"-\"\n",
    "    if (not math.isnan(Repressor[3][i])):\n",
    "        name += str(int(Repressor[4][i]))\n",
    "    name += \"]\"\n",
    "    function = Repressor[8][i]\n",
    "\n",
    "    if (\"HTH lysR-type\" in str(function)):\n",
    "        if(name not in Repressors):\n",
    "            Repressors +=[name]\n",
    "            \n",
    "# print length of list of Activators and Repressors\n",
    "print(len(Activators),len(Repressors))\n",
    "\n",
    "#check for duplicates in list to add to list of bifunctional Proteins\n",
    "\n",
    "duplicates =[]\n",
    "\n",
    "# check if ID in both Activator and Repressor list\n",
    "for i in range(0,len(Activators)):\n",
    "    name = Activators[i]\n",
    "    for j in range(0,len(Repressors)):\n",
    "        name1 = Repressors[j]\n",
    "        if(name == name1):\n",
    "            duplicates += [name]\n",
    "            \n",
    "# print length of duplicate list\n",
    "print(len(duplicates))\n",
    "\n",
    "# remove duplicates from both Activator and Repressor lists\n",
    "for i in range(0,len(duplicates)):\n",
    "    name = duplicates[i]\n",
    "    for j in range(0,len(Activators)):\n",
    "        name1 = Activators[j]\n",
    "        if(name == name1):\n",
    "            del Activators[j]\n",
    "            break\n",
    "    for j in range(0,len(Repressors)):\n",
    "        name1 = Repressors[j]\n",
    "        if(name == name1):\n",
    "            del Repressors[j]\n",
    "            break\n",
    "            \n",
    "# print length of Activator and Repressor list after removal\n",
    "print(len(Activators),len(Repressors))\n",
    "\n",
    "# function to convert list of IDs into string for export\n",
    "def makestring(list):\n",
    "    string = \"\"\n",
    "    for i in range(0,len(list)):\n",
    "        string += str(list[i])\n",
    "        string +=\"\\n\"\n",
    "    return string\n",
    "\n",
    "# make string from list for export\n",
    "StrRepressor = makestring(Repressors)\n",
    "StrActivator = makestring(Activators)\n",
    "StrBoth = makestring(duplicates)\n",
    "\n",
    "# export\n",
    "with open(os.path.join(path,\"Activators_uniprot.txt\"),\"w\") as f:\n",
    "    f.write(StrActivator)\n",
    "with open(os.path.join(path,\"Repressors_uniprot.txt\"),\"w\") as f:\n",
    "    f.write(StrRepressor)\n",
    "with open(os.path.join(path,\"Dual_uniprot.txt\"),\"w\") as f:\n",
    "    f.write(StrBoth)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Phylogenetic analysis\n",
    "\n",
    "Due to the ammount of computational power needed for analysis of all Regulators only 4000 were used in the construction of a phylogenetic tree of the LysR domains. 4000 regulators were randomly selected. All FASTA sequences were manually combined in one file.\n",
    "\n",
    "## Randomly select 4000 sequences for a multiple sequence alignment"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import random\n",
    "\n",
    "#initialize seed \n",
    "random.seed(111)\n",
    "\n",
    "# import all \n",
    "path = os.path.dirname(__file__)\n",
    "with open(os.path.join(path,\"uniprot_full_all.fasta\")) as f:\n",
    "    fasta = f.read()\n",
    "\n",
    "# create list of regulators\n",
    "regulators = fasta.split(\">\")\n",
    "\n",
    "# number of regulators for analysis\n",
    "no_regs = 4000\n",
    "\n",
    "# create string for export\n",
    "fasta1 =\"\"\n",
    "\n",
    "#randomly select 4000 unique regulators by removing from source list\n",
    "for i in range(0,4000):\n",
    "    \n",
    "    random.shuffle(regulators)\n",
    "    seq = regulators.pop(random.randint(0,len(regulators)))\n",
    "    fasta1 +=\">\"\n",
    "    fasta1 += seq\n",
    "\n",
    "#export as fasta file\n",
    "with open(os.path.join(path,\"LysR_sample.fasta\"),\"w\") as f1:\n",
    "    f1.write(fasta1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Multiple sequence alignment\n",
    "\n",
    "Sequences were aligned using ClustalW version 1.2.4 at the EMBL-EBI webserver using the following parameters:\n",
    "* Output guide tree\n",
    "    * true \n",
    "* Output distance matrix\n",
    "    * false \n",
    "* Dealign input sequences\n",
    "    * false \n",
    "* mBed-like clustering guide tree\n",
    "    * true \n",
    "* mBed-like clustering iteration\n",
    "    * true \n",
    "* Number of iterations\n",
    "    * 0 \n",
    "* Maximum guide tree iterations\n",
    "    * -1 \n",
    "* Maximum HMM iterations\n",
    "    * -1 \n",
    "* Output alignment format\n",
    "    * fa \n",
    "* Output order\n",
    "    * aligned \n",
    "* Sequence Type\n",
    "    * protein \n",
    "The resulting multiple sequence aligment was saved as *MSA_LysR.fasta*\n",
    "\n",
    "## Tree construction\n",
    "\n",
    "Using the aligment created in the last step a maximum likelyhood phylogenetic tree was created using MegaX.\n",
    "This tree was created using the following parameters:\n",
    "* Test of phylogeny\n",
    "    * None\n",
    "* Substitution Model\n",
    "    * Jones Taylor Thornton model\n",
    "* ML Heuristic Method\n",
    "    * Nearest Neighbor interchange\n",
    "\n",
    "## Tree visualization\n",
    "Marked in red are Repressors, marked in green are Activators. Blue proteins are both Repressor and Activator."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "constructing tree\n",
      "done\n"
     ]
    }
   ],
   "source": [
    "from ete3 import Tree, faces, AttrFace, TreeStyle, NodeStyle # ete3 is used for tree visualization\n",
    "import pandas as pd\n",
    "import math\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "path = os.path.dirname(__file__)\n",
    "myfile = \"MSA_LysR.fasta\"\n",
    "\n",
    "lookup = pd.read_csv(os.path.join(path,myfile),sep='\\t')\n",
    "\n",
    "#import Tree\n",
    "t = Tree( os.path.join(path,\"LysR_ML.nwk\"))\n",
    "\n",
    "# Uses Activators and Repressors list created as in step 1 as lookup tables\n",
    "\n",
    "Activator = pd.read_csv(os.path.join(path,\"uniprotActivator_all.gff\"), sep= \"\\t\",header= None)\n",
    "Repressor = pd.read_csv(os.path.join(path,\"uniprotRepressor_all.gff\"), sep=\"\\t\",header= None)\n",
    "\n",
    "Activators =[]\n",
    "Repressors =[]\n",
    "\n",
    "\n",
    "for i in range(0,len(Activator)):\n",
    "\n",
    "    name = str(Activator[0][i])\n",
    "\n",
    "\n",
    "    function = Activator[8][i]\n",
    "\n",
    "    if( \"HTH lysR-type\" in str(function)):\n",
    "        if(name not in Activators):\n",
    "            Activators +=[name]\n",
    "\n",
    "for i in range(0,len(Repressor)):\n",
    "\n",
    "    name = str(Repressor[0][i])\n",
    "\n",
    "    function = Repressor[8][i]\n",
    "\n",
    "    if (\"HTH lysR-type\" in str(function)):\n",
    "        if(name not in Repressors):\n",
    "            Repressors +=[name]\n",
    "\n",
    "duplicates =[]\n",
    "for i in range(0,len(Activators)):\n",
    "    name = Activators[i]\n",
    "    for j in range(0,len(Repressors)):\n",
    "        name1 = Repressors[j]\n",
    "        if(name == name1):\n",
    "            duplicates += [name]\n",
    "\n",
    "\n",
    "for i in range(0,len(duplicates)):\n",
    "    name = duplicates[i]\n",
    "    for j in range(0,len(Activators)):\n",
    "        name1 = Activators[j]\n",
    "        if(name == name1):\n",
    "            del Activators[j]\n",
    "            break\n",
    "    for j in range(0,len(Repressors)):\n",
    "        name1 = Repressors[j]\n",
    "        if(name == name1):\n",
    "            del Repressors[j]\n",
    "            break\n",
    "\n",
    "\n",
    "\n",
    "# set styles for nodes\n",
    "Activator_Style = NodeStyle()\n",
    "Activator_Style[\"bgcolor\"] = \"Green\"\n",
    "\n",
    "Repressor_Style = NodeStyle()\n",
    "Repressor_Style[\"bgcolor\"] = \"Red\"\n",
    "\n",
    "Dual_Style = NodeStyle()\n",
    "Dual_Style[\"bgcolor\"] = \"Blue\"\n",
    "\n",
    "print(\"constructing tree\")\n",
    "# set nodestyle depending on Function\n",
    "for n in t.traverse():\n",
    "\n",
    "    if n.is_leaf():\n",
    "        \n",
    "        name = str(n.name).split(\"|\")[1] # set name\n",
    "        \n",
    "        if(name in Activators):\n",
    "            n.set_style(Activator_Style)\n",
    "        if (name in Repressors):\n",
    "            n.set_style(Repressor_Style)\n",
    "        if (name in duplicates):\n",
    "            n.set_style(Dual_Style)\n",
    "        n.name = name\n",
    "        \n",
    "circular_style = TreeStyle()\n",
    "circular_style.mode = \"c\" # draw tree in circular mode\n",
    "\n",
    "#render Tree\n",
    "print(\"done\")\n",
    "t.render(os.path.join(path,\"LysR.pdf\"), tree_style =circular_style)\n",
    "t.show(tree_style =circular_style)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Classifier\n",
    "\n",
    "To classify a sequence as either a Repressor or Activator, Hidden Markov Models were trained. One model was trained on the Repressor sequences, the other on the Activator sequences. Implementation and training of the Hidden Markov Models were done using the python **hmmlearn** library. To predict the function of a gene the models were scored using the score() function. The resulting log likelihood was normalized to the size of the training sample and converted into the likelihood. These likelihoods were compared and a classification was assigned based on comparing the normalized likelihoods.\n",
    "\n",
    "75 percent of the dataset were used for training, 25 percent were used for model validation.\n",
    "\n",
    "Both models were trained for 3000 iterations assuming 14 underlying components.\n",
    "\n",
    "The data was encoded using a numerical system in which the FASTA amino acid code was substituted using integer numbers from 0 to 20.\n",
    "\n",
    "Resulting models were exported using the python **pickle** library."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "started: 2021-03-21 21:48:42.567194\n",
      "starting Training of Activator HMM\n",
      "starting Training of Repressor HMM\n",
      "Done\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "from hmmlearn import hmm\n",
    "import random\n",
    "import pickle\n",
    "from datetime import datetime\n",
    "import json\n",
    "import requests\n",
    "import math\n",
    "\n",
    "\n",
    "# encode FASTA\n",
    "def encode(string):\n",
    "    As = -1\n",
    "    asseq = []\n",
    "    for i in range(0,len(string)):\n",
    "        if(string[i]==\"A\"):\n",
    "            As = 0\n",
    "        elif(string[i]==\"C\"):\n",
    "            As = 1\n",
    "        elif (string[i] == \"D\"):\n",
    "            As = 2\n",
    "        elif (string[i] == \"E\"):\n",
    "            As = 3\n",
    "        elif (string[i] == \"F\"):\n",
    "            As = 4\n",
    "        elif (string[i] == \"G\"):\n",
    "            As = 5\n",
    "        elif (string[i] == \"H\"):\n",
    "            As = 6\n",
    "        elif (string[i] == \"I\"):\n",
    "            As = 7\n",
    "        elif (string[i] == \"K\"):\n",
    "            As = 8\n",
    "        elif (string[i] == \"L\"):\n",
    "            As = 9\n",
    "        elif (string[i] == \"M\"):\n",
    "            As = 10\n",
    "        elif (string[i] == \"N\"):\n",
    "            As = 11\n",
    "        elif (string[i] == \"P\"):\n",
    "            As = 12\n",
    "        elif (string[i] == \"Q\"):\n",
    "            As = 13\n",
    "        elif (string[i] == \"R\"):\n",
    "            As = 14\n",
    "        elif (string[i] == \"S\"):\n",
    "            As = 15\n",
    "        elif (string[i] == \"T\"):\n",
    "            As = 16\n",
    "        elif (string[i] == \"V\"):\n",
    "            As = 17\n",
    "        elif (string[i] == \"W\"):\n",
    "            As = 18\n",
    "        elif (string[i] == \"Y\"):\n",
    "            As = 19\n",
    "        elif (string[i] == \"-\"):\n",
    "            As = 20\n",
    "        asseq +=[As]\n",
    "\n",
    "    return(asseq)\n",
    "\n",
    "iterations = 3000\n",
    "n_components = 14\n",
    "\n",
    "np.random.seed(111)\n",
    "random.seed(111)\n",
    "\n",
    "# import data\n",
    "path = os.path.dirname(__file__)\n",
    "\n",
    "Activator=\"uniprotActivator_all.fasta\"\n",
    "Repressor = \"uniprotRepressor_all.fasta\"\n",
    "now = datetime.now() # get timestamp\n",
    "\n",
    "print(\"started: \"+ str(now))\n",
    "\n",
    "# get sequences\n",
    "with open(os.path.join(path,Activator)) as f:\n",
    "    Activators = f.read()\n",
    "Activators = Activators.split(\">\")\n",
    "\n",
    "with open(os.path.join(path,Repressor)) as f1:\n",
    "    Repressor = f1.read()\n",
    "Repressors = Repressor.split(\">\")\n",
    "\n",
    "Actseq = []\n",
    "Actlen = []\n",
    "Repseq = []\n",
    "Replen = []\n",
    "\n",
    "#encode data\n",
    "for i in range(1,len(Activators)):\n",
    "    t1 = Activators[i].split(\"\\n\")\n",
    "    s =\"\"\n",
    "    for j in range(1,len(t1)):\n",
    "        s += str(t1[j])\n",
    "    s1 = encode(s)\n",
    "    Actseq +=[s1]\n",
    "    Actlen +=[len(s1)]\n",
    "\n",
    "\n",
    "\n",
    "for i in range(1,len(Repressors)):\n",
    "    t1 = Repressors[i].split(\"\\n\")\n",
    "    s =\"\"\n",
    "    for j in range(1,len(t1)):\n",
    "        s += str(t1[j])\n",
    "\n",
    "    s1 = encode(s)\n",
    "    Repseq +=[s1]\n",
    "    Replen += [len(s1)]\n",
    "\n",
    "\n",
    "\n",
    "#split sets into train and test sets\n",
    "trlena = int(len(Actseq)*0.75)\n",
    "trlenr = int(len(Repseq)*0.75)\n",
    "\n",
    "testas = []\n",
    "testal = []\n",
    "\n",
    "original = len(Actseq)-trlena\n",
    "\n",
    "# remove random sequences for testing\n",
    "for i in range(0,original):\n",
    "    index = random.randint(0,len(Actseq)-1)\n",
    "    testas += [Actseq.pop(index)]\n",
    "    testal += [Actlen.pop(index)]\n",
    "\n",
    "testrs = []\n",
    "testrl = []\n",
    "original = len(Repseq)-trlenr\n",
    "for i in range(0,original):\n",
    "    index = random.randint(0,len(Repseq)-1)\n",
    "    testrs += [Repseq.pop(index)]\n",
    "    testrl += [Replen.pop(index)]\n",
    "\n",
    "\n",
    "\n",
    "print(\"starting Training of Activator HMM\")\n",
    "\n",
    "#train models\n",
    "HMMact = hmm.GaussianHMM(n_components=n_components, covariance_type=\"full\", n_iter=iterations)\n",
    "act = []\n",
    "for i in range(0,len(Actseq)):\n",
    "    se = Actseq[i]\n",
    "    act += se\n",
    "\n",
    "npActseq = np.array(act)\n",
    "npActseq = np.vstack(npActseq)\n",
    "HMMact.fit(npActseq,Actlen)\n",
    "\n",
    "\n",
    "print(\"starting Training of Repressor HMM\")\n",
    "\n",
    "\n",
    "HMMrep = hmm.GaussianHMM(n_components=n_components, covariance_type=\"full\", n_iter=iterations)\n",
    "rep = []\n",
    "for i in range(0,len(Repseq)):\n",
    "    se = Repseq[i]\n",
    "    rep += se\n",
    "\n",
    "npRepseq = np.array(rep)\n",
    "npRepseq = np.vstack(npRepseq)\n",
    "\n",
    "HMMrep.fit(npRepseq,Replen)\n",
    "print(\"Done\")\n",
    "\n",
    "time  = str(datetime.now().strftime(\"%Y_%m_%d-%I_%M_%S_%p\"))\n",
    "\n",
    "with open(os.path.join(path,str(time)+\"_Activator.pkl\"), \"wb\") as file:\n",
    "    pickle.dump(HMMact, file)\n",
    "with open(os.path.join(path,str(time)+\"_Repressor.pkl\"), \"wb\") as file1:\n",
    "    pickle.dump(HMMrep, file1)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "started: 2021-03-22 00:13:56.479822\n",
      "finished: 2021-03-22 00:14:04.275652\n",
      "--------------------------------------------\n",
      "Predicted right: 3477\n",
      "Predicted wrong: 20\n",
      "Predicted Activator right: 3176\n",
      "Predicted Repressor right: 301\n",
      "Predicted Activator wrong: 0\n",
      "Predicted Repressor wrong: 20\n",
      "Repression sensitivity: 0.9376947040498442\n",
      "Repression specificity: 1.0\n",
      "Positive predictive value Repression: 1.0\n",
      "Negative predictive value Repression: 0.9937421777221527\n"
     ]
    }
   ],
   "source": [
    "# encode FASTA\n",
    "def encode(string):\n",
    "    As = -1\n",
    "    asseq = []\n",
    "    for i in range(0,len(string)):\n",
    "        if(string[i]==\"A\"):\n",
    "            As = 0\n",
    "        elif(string[i]==\"C\"):\n",
    "            As = 1\n",
    "        elif (string[i] == \"D\"):\n",
    "            As = 2\n",
    "        elif (string[i] == \"E\"):\n",
    "            As = 3\n",
    "        elif (string[i] == \"F\"):\n",
    "            As = 4\n",
    "        elif (string[i] == \"G\"):\n",
    "            As = 5\n",
    "        elif (string[i] == \"H\"):\n",
    "            As = 6\n",
    "        elif (string[i] == \"I\"):\n",
    "            As = 7\n",
    "        elif (string[i] == \"K\"):\n",
    "            As = 8\n",
    "        elif (string[i] == \"L\"):\n",
    "            As = 9\n",
    "        elif (string[i] == \"M\"):\n",
    "            As = 10\n",
    "        elif (string[i] == \"N\"):\n",
    "            As = 11\n",
    "        elif (string[i] == \"P\"):\n",
    "            As = 12\n",
    "        elif (string[i] == \"Q\"):\n",
    "            As = 13\n",
    "        elif (string[i] == \"R\"):\n",
    "            As = 14\n",
    "        elif (string[i] == \"S\"):\n",
    "            As = 15\n",
    "        elif (string[i] == \"T\"):\n",
    "            As = 16\n",
    "        elif (string[i] == \"V\"):\n",
    "            As = 17\n",
    "        elif (string[i] == \"W\"):\n",
    "            As = 18\n",
    "        elif (string[i] == \"Y\"):\n",
    "            As = 19\n",
    "        elif (string[i] == \"-\"):\n",
    "            As = 20\n",
    "        asseq +=[As]\n",
    "\n",
    "    return(asseq)\n",
    "\n",
    "np.random.seed(111)\n",
    "random.seed(111)\n",
    "\n",
    "# import data\n",
    "path = os.path.dirname(__file__)\n",
    "\n",
    "Activator=\"uniprotActivator_all.fasta\"\n",
    "Repressor = \"uniprotRepressor_all.fasta\"\n",
    "now = datetime.now() # get timestamp\n",
    "\n",
    "print(\"started: \"+ str(now))\n",
    "\n",
    "# get sequences\n",
    "with open(os.path.join(path,Activator)) as f:\n",
    "    Activators = f.read()\n",
    "Activators = Activators.split(\">\")\n",
    "\n",
    "with open(os.path.join(path,Repressor)) as f1:\n",
    "    Repressor = f1.read()\n",
    "Repressors = Repressor.split(\">\")\n",
    "\n",
    "Actseq = []\n",
    "Actlen = []\n",
    "Repseq = []\n",
    "Replen = []\n",
    "\n",
    "#encode data\n",
    "for i in range(1,len(Activators)):\n",
    "    t1 = Activators[i].split(\"\\n\")\n",
    "    s =\"\"\n",
    "    for j in range(1,len(t1)):\n",
    "        s += str(t1[j])\n",
    "    s1 = encode(s)\n",
    "    Actseq +=[s1]\n",
    "    Actlen +=[len(s1)]\n",
    "\n",
    "\n",
    "\n",
    "for i in range(1,len(Repressors)):\n",
    "    t1 = Repressors[i].split(\"\\n\")\n",
    "    s =\"\"\n",
    "    for j in range(1,len(t1)):\n",
    "        s += str(t1[j])\n",
    "\n",
    "    s1 = encode(s)\n",
    "    Repseq +=[s1]\n",
    "    Replen += [len(s1)]\n",
    "\n",
    "\n",
    "\n",
    "#split sets into train and test sets\n",
    "trlena = int(len(Actseq)*0.75)\n",
    "trlenr = int(len(Repseq)*0.75)\n",
    "\n",
    "testas = []\n",
    "testal = []\n",
    "\n",
    "original = len(Actseq)-trlena\n",
    "\n",
    "# remove random sequences for testing\n",
    "for i in range(0,original):\n",
    "    index = random.randint(0,len(Actseq)-1)\n",
    "    testas += [Actseq.pop(index)]\n",
    "    testal += [Actlen.pop(index)]\n",
    "\n",
    "testrs = []\n",
    "testrl = []\n",
    "original = len(Repseq)-trlenr\n",
    "for i in range(0,original):\n",
    "    index = random.randint(0,len(Repseq)-1)\n",
    "    testrs += [Repseq.pop(index)]\n",
    "    testrl += [Replen.pop(index)]\n",
    "\n",
    "\n",
    "\n",
    "with open(os.path.join(path,str(time)+\"_Activator.pkl\"), \"rb\") as file: \n",
    "    pickle.load(file)\n",
    "\n",
    "with open(os.path.join(path,str(time)+\"_Repressor.pkl\"), \"rb\") as file: \n",
    "    pickle.load(file)\n",
    "    \n",
    "\n",
    "# test HMM on real data\n",
    "\n",
    "\n",
    "same = 0\n",
    "different = 0\n",
    "guess = 0\n",
    "actpred = 0\n",
    "reppred = 0\n",
    "rightact = 0\n",
    "wrongact = 0\n",
    "rightrep = 0\n",
    "wrongrep = 0\n",
    "testdata = testas + testrs\n",
    "for i in range(0,len(testdata)):\n",
    "\n",
    "    if(len(testas)>0):\n",
    "        data = 0\n",
    "    else:\n",
    "        data = 1\n",
    "    \n",
    "    \n",
    "    if(data == 0):\n",
    "        index = random.randrange(0,len(testas))\n",
    "        seq = testas.pop(index)\n",
    "        seq = np.array(seq)\n",
    "        seq = np.vstack(seq)\n",
    "        \n",
    "    else:\n",
    "        index = random.randrange(0,len(testrs))\n",
    "        seq = testrs.pop(index)\n",
    "        seq = np.array(seq)\n",
    "        seq = np.vstack(seq)\n",
    "        \n",
    "    #average likelyhood\n",
    "    scoreAct = math.exp(HMMact.score(seq)/trlena)\n",
    "    scoreRep = math.exp(HMMrep.score(seq)/trlenr)\n",
    "    \n",
    "    \n",
    "    if(scoreRep> scoreAct):\n",
    "        prediction = 1\n",
    "        reppred += 1\n",
    "    else:\n",
    "        prediction = 0\n",
    "        actpred += 1\n",
    "    \n",
    "    if(data == prediction):\n",
    "        same +=1\n",
    "        if(data == 0):\n",
    "            rightact += 1\n",
    "        if (data == 1):\n",
    "            rightrep += 1\n",
    "    else:\n",
    "        different += 1\n",
    "        if (data == 0):\n",
    "            wrongact += 1\n",
    "        if (data == 1):\n",
    "            wrongrep += 1\n",
    "    \n",
    "\n",
    "\n",
    "now = datetime.now()\n",
    "\n",
    "sensitivityrep = rightrep/(rightrep+wrongrep)\n",
    "specificityrep = rightact/(rightact+wrongact)\n",
    "\n",
    "pospredvalrep = rightrep/(rightrep+wrongact)\n",
    "negpredvalrep = rightact/(rightact+wrongrep)\n",
    "\n",
    "print(\"finished: \" +str(now))\n",
    "print(\"--------------------------------------------\")\n",
    "print(\"Predicted right: \" +str(same)+ \"\\nPredicted wrong: \"+ str(different)+\"\\nPredicted Activator right: \"+ str(rightact)+\"\\nPredicted Repressor right: \"+ str(rightrep))\n",
    "print(\"Predicted Activator wrong: \"+str(wrongact)+\"\\nPredicted Repressor wrong: \"+str(wrongrep))\n",
    "print(\"Repression sensitivity: \"+str(sensitivityrep)+\"\\nRepression specificity: \"+str(specificityrep))\n",
    "print(\"Positive predictive value Repression: \"+str(pospredvalrep)+\"\\nNegative predictive value Repression: \"+ str(negpredvalrep))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
